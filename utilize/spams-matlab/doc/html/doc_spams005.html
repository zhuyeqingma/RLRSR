<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
            "http://www.w3.org/TR/REC-html40/loose.dtd">
<HTML>
<HEAD>

<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<META name="GENERATOR" content="hevea 1.10">

<META name="Author" content="Julien Mairal">
<link rel="stylesheet" href="doc_spams.css">
<LINK rel="stylesheet" type="text/css" href="doc_spams.css">
<TITLE>Proximal Toolbox</TITLE>
</HEAD>
<BODY >
<A HREF="doc_spams004.html"><IMG SRC="previous_motif.gif" ALT="Previous"></A>
<A HREF="index.html"><IMG SRC="contents_motif.gif" ALT="Up"></A>
<A HREF="doc_spams006.html"><IMG SRC="next_motif.gif" ALT="Next"></A>
<HR>
<H2 CLASS="section"><A NAME="htoc18">5</A>  Proximal Toolbox</H2><UL>
<LI><A HREF="doc_spams005.html#toc14">Regularization Functions</A>
</LI><LI><A HREF="doc_spams005.html#toc15">Function mexProximalFlat</A>
</LI><LI><A HREF="doc_spams005.html#toc16">Function mexProximalTree</A>
</LI><LI><A HREF="doc_spams005.html#toc17">Function mexProximalGraph</A>
</LI><LI><A HREF="doc_spams005.html#toc18">Problems Addressed</A>
</LI><LI><A HREF="doc_spams005.html#toc19">Function mexFistaFlat</A>
</LI><LI><A HREF="doc_spams005.html#toc20">Function mexFistaTree</A>
</LI><LI><A HREF="doc_spams005.html#toc21">Function mexFistaGraph</A>
</LI></UL>
<P>
The previous toolbox we have presented is well
adapted for solving a large number of small and medium-scale sparse
decomposition problems with the square loss, which is typical from the
classical dictionary learning framework. We now present
a new software package that is adapted for solving a wide range of
possibly large-scale learning problems, with several combinations of losses and
regularization terms. The method implements the proximal methods
of [<A HREF="doc_spams008.html#beck">1</A>], and includes the proximal solvers for the tree-structured
regularization of [<A HREF="doc_spams008.html#jenatton3">13</A>], and the solver of [<A HREF="doc_spams008.html#mairal10">20</A>] for
general structured sparse regularization.
The solver for structured sparse regularization norms includes a C++ max-flow
implementation of the push-relabel algorithm of [<A HREF="doc_spams008.html#goldberg">11</A>], with
heuristics proposed by [<A HREF="doc_spams008.html#cherkassky">5</A>].</P><P>This implementation also provides robust stopping criteria based on
<EM>duality gaps</EM>, which are presented in Appendix <A HREF="doc_spams007.html#appendix">A</A>. It can handle intercepts (unregularized variables). The general formulation that our software
can solve take the form
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">   </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>w</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> [<I>g</I>(<I><B>w</B></I>) </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=2>▵</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">=</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
</TABLE></TD><TD CLASS="dcell"> <I>f</I>(<I><B>w</B></I>) + λψ(<I><B>w</B></I>)],
</TD></TR>
</TABLE><P>
where <I>f</I> is a smooth loss function and ψ is a regularization function.
When one optimizes a matrix <I><B>W</B></I> in ℝ<SUP><I>p</I> × <I>r</I></SUP> instead of
a vector <I><B>w</B></I> in ℝ<I><SUP>p</SUP></I>, we will write 
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">   </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>W</B></I> ∈ ℝ<SUP><I>p</I> × <I>r</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> [<I>g</I>(<I><B>W</B></I>) </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=2>▵</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">=</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
</TABLE></TD><TD CLASS="dcell"> <I>f</I>(<I><B>W</B></I>) + λψ(<I><B>W</B></I>)].
</TD></TR>
</TABLE><P>
Note that the software can possibly handle nonnegativity constraints.</P><P>We start by presenting the type of regularization implemented in the software
</P><H3 CLASS="subsection"><A NAME="toc14"></A><A NAME="htoc19">5.1</A>  Regularization Functions</H3><P>
Our software can handle the following regularization functions ψ for vectors <I><B>w</B></I> in ℝ<I><SUP>p</SUP></I>:
</P><UL CLASS="itemize"><LI CLASS="li-itemize">
<B>The Tikhonov regularization</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> 1/2||<I><B>w</B></I>||<SUB>2</SUB><SUP>2</SUP>.
</LI><LI CLASS="li-itemize"><B>The ℓ<SUB>1</SUB>-norm</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ||<I><B>w</B></I>||<SUB>1</SUB>.
</LI><LI CLASS="li-itemize"><B>The Elastic-Net</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ||<I><B>w</B></I>||<SUB>1</SUB>+γ||<I><B>w</B></I>||<SUB>2</SUB><SUP>2</SUP>.
</LI><LI CLASS="li-itemize"><B>The Fused-Lasso</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ||<I><B>w</B></I>||<SUB>1</SUB>+γ||<I><B>w</B></I>||<SUB>2</SUB><SUP>2</SUP>+γ<SUB>2</SUB>∑<SUB><I>i</I>=1</SUB><SUP><I>p</I>−1</SUP>|<I><B>w</B></I><SUB><I>i</I>+1</SUB>−<I><B>w</B><SUB>i</SUB></I>|.
</LI><LI CLASS="li-itemize"><B>The group Lasso</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></SUB> η<I><SUB>g</SUB></I> ||<I><B>w</B><SUB>g</SUB></I>||<SUB>2</SUB>, where <FONT COLOR=red><I>G</I></FONT> are groups of variables of the same size.
</LI><LI CLASS="li-itemize"><B>The group Lasso with ℓ<SUB>∞</SUB>-norm</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></SUB> η<I><SUB>g</SUB></I> ||<I><B>w</B><SUB>g</SUB></I>||<SUB>∞</SUB>, where <FONT COLOR=red><I>G</I></FONT> are groups of variables of the same size.
</LI><LI CLASS="li-itemize"><B>The sparse group Lasso</B>: same as above but with an additional ℓ<SUB>1</SUB> term.
</LI><LI CLASS="li-itemize"><B>The tree-structured sum of ℓ<SUB>2</SUB>-norms</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></SUB> η<I><SUB>g</SUB></I> ||<I><B>w</B><SUB>g</SUB></I>||<SUB>2</SUB>, where <FONT COLOR=red><I>G</I></FONT> is a tree-structured set of groups [<A HREF="doc_spams008.html#jenatton3">13</A>], and the η<I><SUB>g</SUB></I> are positive weights.
</LI><LI CLASS="li-itemize"><B>The tree-structured sum of ℓ<SUB>∞</SUB>-norms</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></SUB> η<I><SUB>g</SUB></I> ||<I><B>w</B><SUB>g</SUB></I>||<SUB>∞</SUB>. See [<A HREF="doc_spams008.html#jenatton3">13</A>]
</LI><LI CLASS="li-itemize"><B>General sum of ℓ<SUB>∞</SUB>-norms</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></SUB> η<I><SUB>g</SUB></I> ||<I><B>w</B><SUB>g</SUB></I>||<SUB>∞</SUB>, where no assumption are made on the groups <FONT COLOR=red><I>G</I></FONT>.
</LI></UL><P>
Our software also handles regularization functions ψ on matrices <I><B>W</B></I> in ℝ<SUP><I>p</I> × <I>r</I></SUP> (note that <I><B>W</B></I> can be transposed in these formulations). In particular,
</P><UL CLASS="itemize"><LI CLASS="li-itemize">
<B>The ℓ<SUB>1</SUB>/ℓ<SUB>2</SUB>-norm</B>: ψ(<I><B>W</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>i</I>=1</SUB><I><SUP>p</SUP></I> ||<I><B>W</B><SUB>i</SUB></I>||<SUB>2</SUB>, where <I><B>W</B><SUB>i</SUB></I> denotes the <I>i</I>-th row of <I><B>W</B></I>.
</LI><LI CLASS="li-itemize"><B>The ℓ<SUB>1</SUB>/ℓ<SUB>∞</SUB>-norm</B>: ψ(<I><B>W</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>i</I>=1</SUB><I><SUP>p</SUP></I> ||<I><B>W</B><SUB>i</SUB></I>||<SUB>∞</SUB>,
</LI><LI CLASS="li-itemize"><B>The ℓ<SUB>1</SUB>/ℓ<SUB>2</SUB>+ℓ<SUB>1</SUB>-norm</B>: ψ(<I><B>W</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>i</I>=1</SUB><I><SUP>p</SUP></I> ||<I><B>W</B><SUB>i</SUB></I>||<SUB>2</SUB> + λ<SUB>2</SUB> ∑<SUB><I>i</I>,<I>j</I></SUB>|<I><B>W</B><SUB>ij</SUB></I>|.
</LI><LI CLASS="li-itemize"><B>The ℓ<SUB>1</SUB>/ℓ<SUB>∞</SUB>+ℓ<SUB>1</SUB>-norm</B>: ψ(<I><B>W</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>i</I>=1</SUB><I><SUP>p</SUP></I> ||<I><B>W</B><SUB>i</SUB></I>||<SUB>∞</SUB>+λ<SUB>2</SUB> ∑<SUB><I>i</I>,<I>j</I></SUB>|<I><B>W</B><SUB>ij</SUB></I>|,
</LI><LI CLASS="li-itemize"><B>The ℓ<SUB>1</SUB>/ℓ<SUB>∞</SUB>-norm on rows and columns</B>: ψ(<I><B>W</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>i</I>=1</SUB><I><SUP>p</SUP></I> ||<I><B>W</B><SUB>i</SUB></I>||<SUB>∞</SUB>+λ<SUB>2</SUB> ∑<SUB><I>j</I>=1</SUB><I><SUP>r</SUP></I>||<I><B>W</B><SUP>j</SUP></I>||<SUB>∞</SUB>, where <I><B>W</B><SUP>j</SUP></I> denotes the <I>j</I>-th column of <I><B>W</B></I>.
</LI><LI CLASS="li-itemize"><B>The multi-task tree-structured sum of ℓ<SUB>∞</SUB>-norms</B>: 
<TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
ψ(<I><B>W</B></I>)</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=2>▵</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">=</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>r</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUB>g</SUB></I>||<I><B>w</B><SUB>g</SUB><SUP>i</SUP></I>||<SUB>∞</SUB>+ γ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUB>g</SUB></I> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">max</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I> ∈ <I>g</I></TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>W</B><SUB>j</SUB></I>||<SUB>∞</SUB>,
<A NAME="software:eq:struct"></A>
    (23)</TD></TR>
</TABLE>
where the first double sums is in fact a sum of independent structured norms on the columns <I><B>w</B><SUP>i</SUP></I> of <I><B>W</B></I>, and the right term is a tree-structured regularization norm applied to the ℓ<SUB>∞</SUB>-norm of the rows of <I><B>W</B></I>, thereby inducing the tree-structured regularization at the row level. <FONT COLOR=red><I>G</I></FONT> is here a tree-structured set of groups.
</LI><LI CLASS="li-itemize"><B>The multi-task general sum of ℓ<SUB>∞</SUB>-norms</B> is the same as Eq. (<A HREF="#software:eq:struct">23</A>) except that the groups <FONT COLOR=red><I>G</I></FONT> are general overlapping groups.
</LI><LI CLASS="li-itemize"><B>The trace norm</B>: ψ(<I><B>W</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ||<I><B>W</B></I>||<SUB>*</SUB>.
</LI></UL><P>
Non-convex regularizations are also implemented with the ISTA algorithm (no duality gaps are of course provided in these cases):
</P><UL CLASS="itemize"><LI CLASS="li-itemize">
<B>The ℓ<SUB>0</SUB>-pseudo-norm</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ||<I><B>w</B></I>||<SUB>0</SUB>.
</LI><LI CLASS="li-itemize"><B>The rank</B>: ψ(<I><B>W</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> randk(<I><B>W</B></I>).
</LI><LI CLASS="li-itemize"><B>The tree-structured ℓ<SUB>0</SUB>-pseudo-norm</B>: ψ(<I><B>w</B></I>) =<FONT SIZE=2><SUP>▵</SUP></FONT> ∑<SUB><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></SUB> δ<SUB><I><B>w</B>g</I> ≠ 0</SUB>.
</LI></UL><P>All of these regularization terms for vectors or matrices can be coupled with
nonnegativity constraints. It is also possible to add an intercept, which one
wishes not to regularize, and we will include this possibility in the next
sections. There are also a few hidden undocumented options which are available in the source code.</P><P>We now present 3 functions for computing proximal operators associated to the previous regularization functions.
</P><H3 CLASS="subsection"><A NAME="toc15"></A><A NAME="htoc20">5.2</A>  Function mexProximalFlat</H3><P>
This function computes the proximal operators associated to many regularization functions, for input signals <I><B>U</B></I>=[<I><B>u</B></I><SUP>1</SUP>,…,<I><B>u</B><SUP>n</SUP></I>] in ℝ<SUP><I>p</I> × <I>n</I></SUP>, it finds a matrix <I><B>V</B></I>=[<I><B>v</B></I><SUP>1</SUP>,…,<I><B>v</B><SUP>n</SUP></I>] in ℝ<SUP><I>p</I> × <I>n</I></SUP> such that:</P><P>•  If one chooses a regularization function on vectors, for every column <I><B>u</B></I> of <I><B>U</B></I>, it computes one column <I><B>v</B></I> of <I><B>V</B></I> solving
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ ||<I><B>v</B></I>||<SUB>0</SUB>,
    (24)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ ||<I><B>v</B></I>||<SUB>1</SUB>,
    (25)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ ||<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP>,
    (26)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ ||<I><B>v</B></I>||<SUB>1</SUB> + λ<SUB>2</SUB>||<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP>,
    (27)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I>−1</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell">|<I><B>v</B></I><SUB><I>j</I>+1</SUB><I><SUP>i</SUP></I>−<I><B>v</B><SUB>j</SUB><SUP>i</SUP></I>|+λ<SUB>2</SUB> ||<I><B>v</B></I>||<SUB>1</SUB> + λ<SUB>3</SUB>||<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP>,
    (28)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> δ<I><SUP>g</SUP></I>(<I><B>v</B></I>),
    (29)</TD></TR>
</TABLE><P>
where <FONT COLOR=red><I>T</I></FONT> is a tree-structured set of groups (see [<A HREF="doc_spams008.html#jenatton4">14</A>]), and δ<I><SUP>g</SUP></I>(<I><B>v</B></I>) = 0 if <I><B>v</B><SUB>g</SUB></I>=0 and 1 otherwise.
It can also solve
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB></I>||<SUB>2</SUB>,
    (30)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB></I>||<SUB>∞</SUB>,
    (31)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB></I>||<SUB>∞</SUB>,
    (32)</TD></TR>
</TABLE><P>
where <FONT COLOR=red><I>G</I></FONT> is any kind of set of groups.</P><P>This function can also solve the following proximal operators on matrices
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>V</B></I> ∈ ℝ<SUP><I>p</I> × <I>n</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>U</B></I>−<I><B>V</B></I>||<I><SUB>F</SUB></I><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>V</B><SUB>i</SUB></I>||<SUB>2</SUB>, 
    (33)</TD></TR>
</TABLE><P>
where <I><B>V</B><SUB>i</SUB></I> is the <I>i</I>-th row of <I><B>V</B></I>, or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>V</B></I> ∈ ℝ<SUP><I>p</I> × <I>n</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>U</B></I>−<I><B>V</B></I>||<I><SUB>F</SUB></I><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>V</B><SUB>i</SUB></I>||<SUB>∞</SUB>, 
    (34)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>V</B></I> ∈ ℝ<SUP><I>p</I> × <I>n</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>U</B></I>−<I><B>V</B></I>||<I><SUB>F</SUB></I><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>V</B><SUB>i</SUB></I>||<SUB>2</SUB> +λ<SUB>2</SUB> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> |<I><B>V</B><SUB>ij</SUB></I>|, 
    (35)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>V</B></I> ∈ ℝ<SUP><I>p</I> × <I>n</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>U</B></I>−<I><B>V</B></I>||<I><SUB>F</SUB></I><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>V</B><SUB>i</SUB></I>||<SUB>∞</SUB>+λ<SUB>2</SUB> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> |<I><B>V</B><SUB>ij</SUB></I>|, 
    (36)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>V</B></I> ∈ ℝ<SUP><I>p</I> × <I>n</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>U</B></I>−<I><B>V</B></I>||<I><SUB>F</SUB></I><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>p</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>V</B><SUB>i</SUB></I>||<SUB>∞</SUB>+λ<SUB>2</SUB> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>V</B><SUP>j</SUP></I>||<SUB>∞</SUB>.
    (37)</TD></TR>
</TABLE><P>
where <I><B>V</B><SUP>j</SUP></I> is the <I>j</I>-th column of <I><B>V</B></I>.</P><P>See usage details below:
</P><PRE CLASS="verbatim"><FONT SIZE=2>% 
% Usage:   alpha=mexProximalFlat(U,param);
%
% Name: mexProximalFlat
%
% Description: mexProximalFlat computes proximal operators. Depending
%         on the value of param.regul, it computes 
%
%         Given an input matrix U=[u^1,\ldots,u^n], it computes a matrix 
%         V=[v^1,\ldots,v^n] such that
%         if one chooses a regularization functions on vectors, it computes
%         for each column u of U, a column v of V solving
%         if param.regul='l0'
%             argmin 0.5||u-v||_2^2 + lambda||v||_0
%         if param.regul='l1'
%             argmin 0.5||u-v||_2^2 + lambda||v||_1
%         if param.regul='l2'
%             argmin 0.5||u-v||_2^2 + lambda||v||_2^2
%         if param.regul='elastic-net'
%             argmin 0.5||u-v||_2^2 + lambda||v||_1 + lambda_2||v||_2^2
%         if param.regul='fused-lasso'
%             argmin 0.5||u-v||_2^2 + lambda FL(v) + ...
%                               ...  lambda_2||v||_1 + lambda_3||v||_2^2
%         if param.regul='linf'
%             argmin 0.5||u-v||_2^2 + lambda||v||_inf
%         if param.regul='l2-not-squared'
%             argmin 0.5||u-v||_2^2 + lambda||v||_2
%         if param.regul='group-lasso-l2'  
%             argmin 0.5||u-v||_2^2 + lambda sum_g ||v_g||_2 
%             where the groups are consecutive entries of v of size param.group_size 
%         if param.regul='group-lasso-linf'
%             argmin 0.5||u-v||_2^2 + lambda sum_g ||v_g||_inf
%         if param.regul='sparse-group-lasso-l2'  
%             argmin 0.5||u-v||_2^2 + lambda sum_g ||v_g||_2 + lambda_2 ||v||_1
%             where the groups are consecutive entries of v of size param.group_size 
%         if param.regul='sparse-group-lasso-linf'
%             argmin 0.5||u-v||_2^2 + lambda sum_g ||v_g||_inf + lambda_2 ||v||_1
%         if param.regul='trace-norm-vec' 
%             argmin 0.5||u-v||_2^2 + lambda ||mat(v)||_* 
%            where mat(v) has param.group_size rows
%
%         if one chooses a regularization function on matrices
%         if param.regul='l1l2',  V= 
%             argmin 0.5||U-V||_F^2 + lambda||V||_{1/2}
%         if param.regul='l1linf',  V= 
%             argmin 0.5||U-V||_F^2 + lambda||V||_{1/inf}
%         if param.regul='l1l2+l1',  V= 
%             argmin 0.5||U-V||_F^2 + lambda||V||_{1/2} + lambda_2||V||_{1/1}
%         if param.regul='l1linf+l1',  V= 
%             argmin 0.5||U-V||_F^2 + lambda||V||_{1/inf} + lambda_2||V||_{1/1}
%         if param.regul='l1linf+row-column',  V= 
%             argmin 0.5||U-V||_F^2 + lambda||V||_{1/inf} + lambda_2||V'||_{1/inf}
%         if param.regul='trace-norm',  V= 
%             argmin 0.5||U-V||_F^2 + lambda||V||_*
%         if param.regul='rank',  V= 
%             argmin 0.5||U-V||_F^2 + lambda rank(V)
%         if param.regul='none',  V= 
%             argmin 0.5||U-V||_F^2 
%         
%         for all these regularizations, it is possible to enforce non-negativity constraints
%         with the option param.pos, and to prevent the last row of U to be regularized, with
%         the option param.intercept
%
% Inputs: U:  double m x n matrix   (input signals)
%               m is the signal size
%         param: struct
%               param.lambda  (regularization parameter)
%               param.regul (choice of regularization, see above)
%               param.lambda2  (optional, regularization parameter)
%               param.lambda3  (optional, regularization parameter)
%               param.verbose (optional, verbosity level, false by default)
%               param.intercept (optional, last row of U is not regularized,
%                 false by default)
%               param.transpose (optional, transpose the matrix in the regularizaiton function)
%               param.group_size (optional, for regularization functions assuming a group
%                 structure)
%               param.pos (optional, adds positivity constraints on the
%                 coefficients, false by default)
%               param.numThreads (optional, number of threads for exploiting
%                 multi-core / multi-cpus. By default, it takes the value -1,
%                 which automatically selects all the available CPUs/cores).
%
% Output: alpha: double m x n matrix (output coefficients)
%
% Author: Julien Mairal, 2010


</FONT></PRE><H3 CLASS="subsection"><A NAME="toc16"></A><A NAME="htoc21">5.3</A>  Function mexProximalTree</H3><P>
This function computes the proximal operators associated to tree-structured regularization functions, for input signals <I><B>U</B></I>=[<I><B>u</B></I><SUP>1</SUP>,…,<I><B>u</B><SUP>n</SUP></I>] in ℝ<SUP><I>p</I> × <I>n</I></SUP>, and a tree-structured set of groups [<A HREF="doc_spams008.html#jenatton3">13</A>], it computes a matrix <I><B>V</B></I>=[<I><B>v</B></I><SUP>1</SUP>,…,<I><B>v</B><SUP>n</SUP></I>] in ℝ<SUP><I>p</I> × <I>n</I></SUP>. When one uses a regularization function on vectors, it computes a column <I><B>v</B></I> of <I><B>V</B></I> for every column <I><B>u</B></I> of <I><B>U</B></I>:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB></I>||<SUB>2</SUB>,
    (38)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB></I>||<SUB>∞</SUB>,
    (39)</TD></TR>
</TABLE><P>
or
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> δ<I><SUP>g</SUP></I>(<I><B>v</B></I>),
    (40)</TD></TR>
</TABLE><P>
where δ<I><SUP>g</SUP></I>(<I><B>v</B></I>)=0 if <I><B>v</B><SUB>g</SUB></I>=0 and 1 otherwise (see appendix of [<A HREF="doc_spams008.html#jenatton4">14</A>]).</P><P>When the multi-task tree-structured regularization function is used, it solves
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>V</B></I> ∈ ℝ<SUP><I>p</I>× <I>n</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>U</B></I>−<I><B>V</B></I>||<I><SUB>F</SUB></I><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB><SUP>i</SUP></I>||<SUB>∞</SUB>+ λ<SUB>2</SUB></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>T</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">max</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I> ∈ <I>g</I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>v</B><SUB>g</SUB><SUP>j</SUP></I>||<SUB>∞</SUB>,
    (41)</TD></TR>
</TABLE><P> 
which is a formulation presented in [<A HREF="doc_spams008.html#mairal10">20</A>].</P><P>This function can also be used for computing the proximal operators addressed by mexProximalFlat (it will just not take into account the tree structure). The way the tree is incoded is presented below, (and examples are given in the file test_ProximalTree.m, with more usage details:
</P><PRE CLASS="verbatim"><FONT SIZE=2>% 
% Usage:   alpha=mexProximalTree(U,tree,param);
%
% Name: mexProximalTree
%
% Description: mexProximalTree computes a proximal operator. Depending
%         on the value of param.regul, it computes 
%
%         Given an input matrix U=[u^1,\ldots,u^n], and a tree-structured set of groups T,
%         it returns a matrix V=[v^1,\ldots,v^n]:
%         
%         when the regularization function is for vectors,
%         for every column u of U, it compute a column v of V solving
%         if param.regul='tree-l0'
%             argmin 0.5||u-v||_2^2 + lambda \sum_{g \in T} \delta^g(v)
%         if param.regul='tree-l2'
%           for all i, v^i = 
%             argmin 0.5||u-v||_2^2 + lambda\sum_{g \in T} \eta_g||v_g||_2
%         if param.regul='tree-linf'
%           for all i, v^i = 
%             argmin 0.5||u-v||_2^2 + lambda\sum_{g \in T} \eta_g||v_g||_inf
%
%         when the regularization function is for matrices:
%         if param.regul='multi-task-tree'
%            V=argmin 0.5||U-V||_F^2 + lambda \sum_{i=1}^n\sum_{g \in T} \eta_g||v^i_g||_inf + ...
%                                                lambda_2 \sum_{g \in T} \eta_g max_{j in g}||V_j||_{inf}
%         
%         it can also be used with any non-tree-structured regularization addressed by mexProximalFlat
%
%         for all these regularizations, it is possible to enforce non-negativity constraints
%         with the option param.pos, and to prevent the last row of U to be regularized, with
%         the option param.intercept
%
% Inputs: U:  double m x n matrix   (input signals)
%               m is the signal size
%         tree: struct
%               with four fields, eta_g, groups, own_variables and N_own_variables.
%
%               The tree structure requires a particular organization of groups and variables
%                  * Let us denote by N = |T|, the number of groups.
%                    the groups should be ordered T={g1,g2,\ldots,gN} such that if gi is included
%                    in gj, then j &lt;= i. g1 should be the group at the root of the tree 
%                    and contains every variable.
%                  * Every group is a set of  contiguous indices for instance 
%                    gi={3,4,5} or gi={4,5,6,7} or gi={4}, but not {3,5};
%                  * We define root(gi) as the indices of the variables that are in gi,
%                    but not in its descendants. For instance for
%                    T={ g1={1,2,3,4},g2={2,3},g3={4} }, then, root(g1)={1}, 
%                    root(g2)={2,3}, root(g3)={4},
%                    We assume that for all i, root(gi) is a set of contigous variables
%                  * We assume that the smallest of root(gi) is also the smallest index of gi.
%
%                  For instance, 
%                    T={ g1={1,2,3,4},g2={2,3},g3={4} }, is a valid set of groups.
%                    but we can not have
%                    T={ g1={1,2,3,4},g2={1,2},g3={3} }, since root(g1)={4} and 4 is not the
%                    smallest element in g1.
%
%               We do not lose generality with these assumptions since they can be fullfilled for any
%               tree-structured set of groups after a permutation of variables and a correct ordering of the
%               groups.
%               see more examples in test_ProximalTree.m of valid tree-structured sets of groups.
%               
%               The first fields sets the weights for every group
%                  tree.eta_g            double N vector 
%  
%               The next field sets inclusion relations between groups 
%               (but not between groups and variables):
%                  tree.groups           sparse (double or boolean) N x N matrix  
%                  the (i,j) entry is non-zero if and only if i is different than j and 
%                  gi is included in gj.
%                  the first column corresponds to the group at the root of the tree.
%
%               The next field define the smallest index of each group gi, 
%               which is also the smallest index of root(gi)
%               tree.own_variables    int32 N vector
%
%               The next field define for each group gi, the size of root(gi)
%               tree.N_own_variables  int32 N vector 
%
%               examples are given in test_ProximalTree.m
%
%         param: struct
%               param.lambda  (regularization parameter)
%               param.regul (choice of regularization, see above)
%               param.lambda2  (optional, regularization parameter)
%               param.lambda3  (optional, regularization parameter)
%               param.verbose (optional, verbosity level, false by default)
%               param.intercept (optional, last row of U is not regularized,
%                 false by default)
%               param.pos (optional, adds positivity constraints on the
%                 coefficients, false by default)
%               param.numThreads (optional, number of threads for exploiting
%                 multi-core / multi-cpus. By default, it takes the value -1,
%                 which automatically selects all the available CPUs/cores).
%
% Output: alpha: double m x n matrix (output coefficients)
%
% Author: Julien Mairal, 2010


</FONT></PRE><H3 CLASS="subsection"><A NAME="toc17"></A><A NAME="htoc22">5.4</A>  Function mexProximalGraph</H3><P>
This function computes the proximal operators associated to structured sparse regularization, for input signals <I><B>U</B></I>=[<I><B>u</B></I><SUP>1</SUP>,…,<I><B>u</B><SUP>n</SUP></I>] in ℝ<SUP><I>p</I> × <I>n</I></SUP>, and a set of groups [<A HREF="doc_spams008.html#mairal10">20</A>], it returns a matrix <I><B>V</B></I>=[<I><B>v</B></I><SUP>1</SUP>,…,<I><B>v</B><SUP>n</SUP></I>] in ℝ<SUP><I>p</I> × <I>n</I></SUP>.
When one uses a regularization function on vectors, it computes a column <I><B>v</B></I> of <I><B>V</B></I> for every column <I><B>u</B></I> of <I><B>U</B></I>:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>v</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>u</B></I>−<I><B>v</B></I>||<SUB>2</SUB><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB></I>||<SUB>∞</SUB>,
    (42)</TD></TR>
</TABLE><P>
or with a regularization function on matrices, it computes <I><B>V</B></I> solving
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>V</B></I> ∈ ℝ<SUP><I>p</I>× <I>n</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>U</B></I>−<I><B>V</B></I>||<I><SUB>F</SUB></I><SUP>2</SUP> + λ </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> η<I><SUP>g</SUP></I> ||<I><B>v</B><SUB>g</SUB><SUP>i</SUP></I>||<SUB>∞</SUB>+ λ<SUB>2</SUB></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>g</I> ∈ <FONT COLOR=red><I>G</I></FONT></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">max</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I> ∈ <I>g</I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>v</B><SUB>g</SUB><SUP>j</SUP></I>||<SUB>∞</SUB>,
    (43)</TD></TR>
</TABLE><P> 
This function can also be used for computing the proximal operators addressed by mexProximalFlat. The way the graph is incoded is presented below (and also in the example file test_ProximalGraph.m, with more usage details:</P><PRE CLASS="verbatim"><FONT SIZE=2>% 
% Usage:   alpha=mexProximalGraph(U,graph,param);
%
% Name: mexProximalGraph
%
% Description: mexProximalGraph computes a proximal operator. Depending
%         on the value of param.regul, it computes 
%
%         Given an input matrix U=[u^1,\ldots,u^n], and a set of groups G,
%         it computes a matrix V=[v^1,\ldots,v^n] such that
%
%         if param.regul='graph'
%         for every column u of U, it computes a column v of V solving
%             argmin 0.5||u-v||_2^2 + lambda\sum_{g \in G} \eta_g||v_g||_inf
%
%         if param.regul='graph+ridge'
%         for every column u of U, it computes a column v of V solving
%             argmin 0.5||u-v||_2^2 + lambda\sum_{g \in G} \eta_g||v_g||_inf + lambda_2||v||_2^2
%
%
%         if param.regul='multi-task-graph'
%            V=argmin 0.5||U-V||_F^2 + lambda \sum_{i=1}^n\sum_{g \in G} \eta_g||v^i_g||_inf + ...
%                                                lambda_2 \sum_{g \in G} \eta_g max_{j in g}||V_j||_{inf}
%         
%         it can also be used with any regularization addressed by mexProximalFlat
%
%         for all these regularizations, it is possible to enforce non-negativity constraints
%         with the option param.pos, and to prevent the last row of U to be regularized, with
%         the option param.intercept
%
% Inputs: U:  double p x n matrix   (input signals)
%               m is the signal size
%         graph: struct
%               with three fields, eta_g, groups, and groups_var
%
%               The first fields sets the weights for every group
%                  graph.eta_g            double N vector 
%  
%               The next field sets inclusion relations between groups 
%               (but not between groups and variables):
%                  graph.groups           sparse (double or boolean) N x N matrix  
%                  the (i,j) entry is non-zero if and only if i is different than j and 
%                  gi is included in gj.
%               
%               The next field sets inclusion relations between groups and variables
%                  graph.groups_var       sparse (double or boolean) p x N matrix
%                  the (i,j) entry is non-zero if and only if the variable i is included 
%                  in gj, but not in any children of gj.
%
%               examples are given in test_ProximalGraph.m
%
%         param: struct
%               param.lambda  (regularization parameter)
%               param.regul (choice of regularization, see above)
%               param.lambda2  (optional, regularization parameter)
%               param.lambda3  (optional, regularization parameter)
%               param.verbose (optional, verbosity level, false by default)
%               param.intercept (optional, last row of U is not regularized,
%                 false by default)
%               param.pos (optional, adds positivity constraints on the
%                 coefficients, false by default)
%               param.numThreads (optional, number of threads for exploiting
%                 multi-core / multi-cpus. By default, it takes the value -1,
%                 which automatically selects all the available CPUs/cores).
%
% Output: alpha: double p x n matrix (output coefficients)
%
% Author: Julien Mairal, 2010


</FONT></PRE><P>After having presented the regularization terms which our software can handle,
we present the various formulations that we address
</P><H3 CLASS="subsection"><A NAME="toc18"></A><A NAME="htoc23">5.5</A>  Problems Addressed</H3><P>
We present here regression or classification formulations and their multi-task variants.
</P><H4 CLASS="subsubsection"><A NAME="htoc24">5.5.1</A>  Regression Problems with the Square Loss</H4><P> Given a training set {<I><B>x</B><SUP>i</SUP></I>,<I>y<SUB>i</SUB></I>}<SUB><I>i</I>=1</SUB><I><SUP>n</SUP></I>, with <I><B>x</B><SUP>i</SUP></I> ∈ ℝ<I><SUP>p</SUP></I> and <I>y<SUB>i</SUB></I> ∈ ℝ for all <I>i</I> in [ 1;<I>n</I> ], we address
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>w</B></I> ∈ ℝ<I><SUP>p</SUP></I>, <I>b</I> ∈ ℝ</TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">(<I>y<SUB>i</SUB></I>−<I><B>w</B></I><SUP>⊤</SUP><I><B>x</B><SUP>i</SUP></I>−<I>b</I>)<SUP>2</SUP> + λψ(<I><B>w</B></I>),
</TD></TR>
</TABLE><P>
where <I>b</I> is an optional variable acting as an “intercept”, which is not regularized, and ψ
can be any of the regularization functions presented above. 
Let us consider the vector <I><B>y</B></I> in ℝ<I><SUP>n</SUP></I> that carries the entries <I>y<SUB>i</SUB></I>. 
The problem without the intercept takes the following form, which we have already
encountered in the previous toolbox, but with different notations:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>w</B></I> ∈ ℝ<I><SUP>p</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">||<I><B>y</B></I>−<B><I>Xw</I></B>||<SUB>2</SUB><SUP>2</SUP> + λψ(<I><B>w</B></I>),
</TD></TR>
</TABLE><P>
where the <I><B>X</B></I>=[<I><B>x</B><SUP>i</SUP></I>,…,<I><B>x</B><SUP>n</SUP></I>]<I><SUP>T</SUP></I> (the <I><B>x</B><SUP>i</SUP></I>’s are here the rows of <I><B>X</B></I>).
</P><H4 CLASS="subsubsection"><A NAME="htoc25">5.5.2</A>  Classification Problems with the Logistic Loss</H4><P>
The next formulation that our software can solve is the regularized logistic regression formulation.
We are again given a training set {<I><B>x</B><SUP>i</SUP></I>,<I>y<SUB>i</SUB></I>}<SUB><I>i</I>=1</SUB><I><SUP>n</SUP></I>, with <I><B>x</B><SUP>i</SUP></I> ∈
ℝ<I><SUP>p</SUP></I>, but the variables <I>y<SUB>i</SUB></I> are now in {−1,+1} for all <I>i</I> in
[ 1;<I>n</I> ]. The optimization problem we address is
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>w</B></I> ∈ ℝ<I><SUP>p</SUP></I>, <I>b</I> ∈ ℝ</TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> log(1+<I>e</I><SUP>−<I>y<SUB>i</SUB></I>(<B><I>w</I></B>⊤<I><B>x</B>i</I>+<I>b</I>)</SUP> + λψ(<I><B>w</B></I>),
</TD></TR>
</TABLE><P>
with again ψ taken to be one of the regularization function presented above, and <I>b</I> is an optional intercept.
</P><H4 CLASS="subsubsection"><A NAME="htoc26">5.5.3</A>  Multi-class Classification Problems with the Softmax Loss</H4><P>
We have also implemented a multi-class logistic classifier (or softmax).
For a classification problem with <I>r</I> classes, we are given a training set {<I><B>x</B><SUP>i</SUP></I>,<I>y<SUB>i</SUB></I>}<SUB><I>i</I>=1</SUB><I><SUP>n</SUP></I>, where the variables <I><B>x</B><SUP>i</SUP></I> are still vectors in ℝ<I><SUP>p</SUP></I>, but the <I>y<SUB>i</SUB></I>’s have integer values in {1,2,…,<I>r</I>}. The formulation we address is the following multi-class learning problem
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">
</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>W</B></I> ∈ ℝ<SUP><I>p</I> × <I>r</I></SUP>, <I><B>b</B></I> ∈ ℝ<I><SUP>r</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> log</TD><TD CLASS="dcell">⎛<BR>
⎜<BR>
⎝</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>r</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> <I>e</I><SUP> (<I><B>w</B>j</I>−<I><B>wy</B><SUB>i</SUB></I>)⊤<I><B>x</B>i</I> + <I><B>b</B><SUB>j</SUB></I>−<I><B>b</B><SUB><B>y</B>i</SUB></I></SUP></TD><TD CLASS="dcell">⎞<BR>
⎟<BR>
⎠</TD><TD CLASS="dcell">+ λ</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>r</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell">ψ(<I><B>w</B><SUP>j</SUP></I>),<A NAME="software:eq:class"></A>
    (44)</TD></TR>
</TABLE><P>
where <I><B>W</B></I> = [<I><B>w</B></I><SUP>1</SUP>,…,<I><B>w</B><SUP>r</SUP></I>] and the optional vector <I><B>b</B></I> in ℝ<I><SUP>r</SUP></I> carries intercepts for each class.
</P><H4 CLASS="subsubsection"><A NAME="htoc27">5.5.4</A>  Multi-task Regression Problems with the Square Loss</H4><P>
We are now considering a problem with <I>r</I> tasks, and a training set
{<I><B>x</B><SUP>i</SUP></I>,<I><B>y</B><SUP>i</SUP></I>}<SUB><I>i</I>=1</SUB><I><SUP>n</SUP></I>, where the variables <I><B>x</B><SUP>i</SUP></I> are still vectors in ℝ<I><SUP>p</SUP></I>, and <I><B>y</B><SUP>i</SUP></I>
is a vector in ℝ<I><SUP>r</SUP></I>. We are looking for <I>r</I> regression vectors <I><B>w</B><SUP>j</SUP></I>, for <I>j</I>∈ [ 1;<I>r</I> ], or equivalently for a matrix <I><B>W</B></I>=[<I><B>w</B></I><SUP>1</SUP>,…,<I><B>w</B><SUP>r</SUP></I>] in ℝ<SUP><I>p</I> × <I>r</I></SUP>. The formulation we address is the following
multi-task regression problem
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>W</B></I> ∈ ℝ<SUP><I>p</I> × <I>r</I></SUP>, <I><B>b</B></I> ∈ ℝ<I><SUP>r</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>r</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell">(<I><B>y</B><SUB>j</SUB><SUP>i</SUP></I>−<I><B>w</B></I><SUP>⊤</SUP><I><B>x</B><SUP>i</SUP></I>−<I><B>b</B><SUB>j</SUB></I>)<SUP>2</SUP> + λψ(<I><B>W</B></I>),
</TD></TR>
</TABLE><P>
where ψ is any of the regularization function on matrices we have presented in the previous section.
Note that by introducing the appropriate variables <I><B>Y</B></I>, the problem without intercept could be equivalently rewritten
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">   </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>W</B></I> ∈ ℝ<SUP><I>p</I> × <I>r</I></SUP></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">2</TD></TR>
</TABLE></TD><TD CLASS="dcell"> ||<I><B>Y</B></I>−<B><I>XW</I></B>||<SUB>F</SUB><SUP>2</SUP> + λψ(<I><B>W</B></I>).
</TD></TR>
</TABLE><H4 CLASS="subsubsection"><A NAME="htoc28">5.5.5</A>  Multi-task Classification Problems with the Logistic Loss</H4><P>
The multi-task version of the logistic regression follows the same principle.
We consider <I>r</I> tasks, and a training set
{<I><B>x</B><SUP>i</SUP></I>,<I><B>y</B><SUP>i</SUP></I>}<SUB><I>i</I>=1</SUB><I><SUP>n</SUP></I>, with the <I><B>x</B><SUP>i</SUP></I>’s in ℝ<I><SUP>p</SUP></I>, and the <I><B>y</B><SUP>i</SUP></I>’s
are vectors in {−1,+1}<I><SUP>r</SUP></I>. We look for a matrix <I><B>W</B></I>=[<I><B>w</B></I><SUP>1</SUP>,…,<I><B>w</B><SUP>r</SUP></I>] in ℝ<SUP><I>p</I> × <I>r</I></SUP>. The formulation is the following
multi-task regression problem
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>W</B></I> ∈ ℝ<SUP><I>p</I> × <I>r</I></SUP>, <I><B>b</B></I> ∈ ℝ<I><SUP>r</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>r</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> log</TD><TD CLASS="dcell">⎛<BR>
⎜<BR>
⎝</TD><TD CLASS="dcell">1+<I>e</I><SUP>−<I><B>y</B><SUB>j</SUB>i</I>(<B><I>w</I></B>⊤<I><B>x</B>i</I>+<I><B>b</B><SUB>j</SUB></I>)</SUP></TD><TD CLASS="dcell">⎞<BR>
⎟<BR>
⎠</TD><TD CLASS="dcell">+ λψ(<I><B>W</B></I>).
</TD></TR>
</TABLE><H4 CLASS="subsubsection"><A NAME="htoc29">5.5.6</A>  Multi-task and Multi-class Classification Problems with the Softmax Loss</H4><P>
The multi-task/multi-class version directly follows from the formulation of Eq. (<A HREF="#software:eq:class">44</A>), but associates with each class a task, and as a consequence, regularizes the matrix <I><B>W</B></I> in a particular way:
</P><TABLE CLASS="display dcenter"><TR VALIGN="middle"><TD CLASS="dcell">    </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">&nbsp;</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center">min</TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I><B>W</B></I> ∈ ℝ<SUP><I>p</I> × <I>r</I></SUP>, <I><B>b</B></I> ∈ ℝ<I><SUP>r</SUP></I></TD></TR>
</TABLE></TD><TD CLASS="dcell"> </TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center">1</TD></TR>
<TR><TD CLASS="hbar"></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
</TABLE></TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>n</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>i</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> log</TD><TD CLASS="dcell">⎛<BR>
⎜<BR>
⎝</TD><TD CLASS="dcell"><TABLE CLASS="display"><TR><TD CLASS="dcell" ALIGN="center"><I>r</I></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><FONT SIZE=6>∑</FONT></TD></TR>
<TR><TD CLASS="dcell" ALIGN="center"><I>j</I>=1</TD></TR>
</TABLE></TD><TD CLASS="dcell"> <I>e</I><SUP> (<I><B>w</B>j</I>−<I><B>wy</B><SUB>i</SUB></I>)⊤<I><B>x</B>i</I> + <I><B>b</B><SUB>j</SUB></I>−<I><B>b</B><SUB><B>y</B>i</SUB></I></SUP></TD><TD CLASS="dcell">⎞<BR>
⎟<BR>
⎠</TD><TD CLASS="dcell">+ λψ(<I><B>W</B></I>).
</TD></TR>
</TABLE><P>
How duality gaps are computed for any of these formulations is presented in Appendix <A HREF="doc_spams007.html#appendix">A</A>.
We now present the main functions for solving these problems</P><H3 CLASS="subsection"><A NAME="toc19"></A><A NAME="htoc30">5.6</A>  Function mexFistaFlat</H3><P>
Given a matrix <I><B>X</B></I>=[<I><B>x</B></I><SUP>1</SUP>,…,<I><B>x</B><SUP>p</SUP></I>]<I><SUP>T</SUP></I> in ℝ<SUP><I>m</I> × <I>p</I></SUP>, and a matrix <I><B>Y</B></I>=[<I><B>y</B></I><SUP>1</SUP>,…,<I><B>y</B><SUP>n</SUP></I>], it solves the optimization problems presented in the previous section, with the same regularization functions as mexProximalFlat.
see usage details below:</P><PRE CLASS="verbatim"><FONT SIZE=2>% 
% Usage: W=mexFistaFlat(Y,X,W0,param);
%
% Name: mexFistaFlat
%
% Description: mexFistaFlat solves sparse regularized problems.
%         X is a design matrix of size m x p
%         X=[x^1,...,x^n]', where the x_i's are the rows of X
%         Y=[y^1,...,y^n] is a matrix of size m x n
%         It implements the algorithms FISTA, ISTA and subgradient descent.
%         
%           - if param.loss='square' and param.regul is a regularization function for vectors,
%             the entries of Y are real-valued,  W = [w^1,...,w^n] is a matrix of size p x n
%             For all column y of Y, it computes a column w of W such that
%               w = argmin 0.5||y- X w||_2^2 + lambda psi(w)
%
%           - if param.loss='square' and param.regul is a regularization function for matrices
%             the entries of Y are real-valued,  W is a matrix of size p x n. 
%             It computes the matrix W such that
%               W = argmin 0.5||Y- X W||_F^2 + lambda psi(W)
%            
%           - param.loss='square-missing' : same as param.loss='square', but handles missing data
%             represented by NaN (not a number) in the matrix Y
%
%           - if param.loss='logistic' and param.regul is a regularization function for vectors,
%             the entries of Y are either -1 or +1, W = [w^1,...,w^n] is a matrix of size p x n
%             For all column y of Y, it computes a column w of W such that
%               w = argmin (1/m)sum_{j=1}^m log(1+e^(-y_j x^j' w)) + lambda psi(w),
%             where x^j is the j-th row of X.
%
%           - if param.loss='logistic' and param.regul is a regularization function for matrices
%             the entries of Y are either -1 or +1, W is a matrix of size p x n
%               W = argmin sum_{i=1}^n(1/m)sum_{j=1}^m log(1+e^(-y^i_j x^j' w^i)) + lambda psi(W)
%
%           - if param.loss='multi-logistic' and param.regul is a regularization function for vectors,
%             the entries of Y are in {0,1,...,N} where N is the total number of classes
%             W = [W^1,...,W^n] is a matrix of size p x Nn, each submatrix W^i is of size p x N
%             for all submatrix WW of W, and column y of Y, it computes
%               WW = argmin (1/m)sum_{j=1}^m log(sum_{j=1}^r e^(x^j'(ww^j-ww^{y_j}))) + lambda sum_{j=1}^N psi(ww^j),
%             where ww^j is the j-th column of WW.
%
%           - if param.loss='multi-logistic' and param.regul is a regularization function for matrices,
%             the entries of Y are in {0,1,...,N} where N is the total number of classes
%             W is a matrix of size p x N, it computes
%               W = argmin (1/m)sum_{j=1}^m log(sum_{j=1}^r e^(x^j'(w^j-w^{y_j}))) + lambda psi(W)
%             where ww^j is the j-th column of WW.
%
%           - param.loss='cur' : useful to perform sparse CUR matrix decompositions, 
%               W = argmin 0.5||Y-X*W*X||_F^2 + lambda psi(W)
%
%
%         The function psi are those used by mexProximalFlat (see documentation)
%
%         This function can also handle intercepts (last row of W is not regularized),
%         and/or non-negativity constraints on W, and sparse matrices for X
%
% Inputs: Y:  double dense m x n matrix
%         X:  double dense or sparse m x p matrix   
%         W0:  double dense p x n matrix or p x Nn matrix (for multi-logistic loss)
%              initial guess
%         param: struct
%            param.loss (choice of loss, see above)
%            param.regul (choice of regularization, see function mexProximalFlat)
%            param.lambda (regularization parameter)
%            param.lambda2 (optional, regularization parameter, 0 by default)
%            param.lambda3 (optional, regularization parameter, 0 by default)
%            param.verbose (optional, verbosity level, false by default)
%            param.intercept (optional, last row of U is not regularized,
%                false by default)
%            param.pos (optional, adds positivity constraints on the
%                coefficients, false by default)
%            param.numThreads (optional, number of threads for exploiting
%                multi-core / multi-cpus. By default, it takes the value -1,
%                which automatically selects all the available CPUs/cores).
%            param.max_it (optional, maximum number of iterations, 100 by default)
%            param.tol (optional, tolerance for stopping criteration, which is a relative duality gap
%                if it is available, or a relative change of parameters).
%            param.gamma (optional, multiplier for increasing the parameter L in fista, 1.5 by default)
%            param.L0 (optional, initial parameter L in fista, 0.1 by default, should be small enough)
%            param.fixed_step (deactive the line search for L in fista and use param.L0 instead)
%            param.compute_gram (optional, pre-compute X^TX, false by default).
%            param.intercept (optional, do not regularize last row of W, false by default).
%            param.ista (optional, use ista instead of fista, false by default).
%            param.subgrad (optional, if not param.ista, use subradient descent instead of fista, false by default).
%            param.a, param.b (optional, if param.subgrad, the gradient step is a/(t+b)
%            also similar options as mexProximalFlat
%
%            the function also implements the ADMM algorithm via an option param.admm=true. It is not documented
%            and you need to look at the source code to use it.
%
% Output:  W:  double dense p x n matrix or p x Nn matrix (for multi-logistic loss)
%
% Author: Julien Mairal, 2010


</FONT></PRE><H3 CLASS="subsection"><A NAME="toc20"></A><A NAME="htoc31">5.7</A>  Function mexFistaTree</H3><P>
Given a matrix <I><B>X</B></I>=[<I><B>x</B></I><SUP>1</SUP>,…,<I><B>x</B><SUP>p</SUP></I>]<I><SUP>T</SUP></I> in ℝ<SUP><I>m</I> × <I>p</I></SUP>, and a matrix <I><B>Y</B></I>=[<I><B>y</B></I><SUP>1</SUP>,…,<I><B>y</B><SUP>n</SUP></I>], it solves the optimization problems presented in the previous section, with the same regularization functions as mexProximalTree.
see usage details below:</P><PRE CLASS="verbatim"><FONT SIZE=2>% 
% Usage: W=mexFistaTree(Y,X,W0,tree,param);
%
% Name: mexFistaTree
%
% Description: mexFistaTree solves sparse regularized problems.
%         X is a design matrix of size m x p
%         X=[x^1,...,x^n]', where the x_i's are the rows of X
%         Y=[y^1,...,y^n] is a matrix of size m x n
%         It implements the algorithms FISTA, ISTA and subgradient descent for solving
%
%           min_W  loss(W) + lambda psi(W)
%          
%         The function psi are those used by mexProximalTree (see documentation)
%         for the loss functions, see the documentation of mexFistaFlat
%
%         This function can also handle intercepts (last row of W is not regularized),
%         and/or non-negativity constraints on W and sparse matrices X
%
% Inputs: Y:  double dense m x n matrix
%         X:  double dense or sparse m x p matrix   
%         W0:  double dense p x n matrix or p x Nn matrix (for multi-logistic loss)
%              initial guess
%         tree: struct (see documentation of mexProximalTree)
%         param: struct
%            param.loss (choice of loss, see above)
%            param.regul (choice of regularization, see function mexProximalFlat)
%            param.lambda (regularization parameter)
%            param.lambda2 (optional, regularization parameter, 0 by default)
%            param.lambda3 (optional, regularization parameter, 0 by default)
%            param.verbose (optional, verbosity level, false by default)
%            param.intercept (optional, last row of U is not regularized,
%                false by default)
%            param.pos (optional, adds positivity constraints on the
%                coefficients, false by default)
%            param.numThreads (optional, number of threads for exploiting
%                multi-core / multi-cpus. By default, it takes the value -1,
%                which automatically selects all the available CPUs/cores).
%            param.max_it (optional, maximum number of iterations, 100 by default)
%            param.tol (optional, tolerance for stopping criteration, which is a relative duality gap
%                if it is available, or a relative change of parameters).
%            param.gamma (optional, multiplier for increasing the parameter L in fista, 1.5 by default)
%            param.L0 (optional, initial parameter L in fista, 0.1 by default, should be small enough)
%            param.fixed_step (deactive the line search for L in fista and use param.L0 instead)
%            param.compute_gram (optional, pre-compute X^TX, false by default).
%            param.intercept (optional, do not regularize last row of W, false by default).
%            param.ista (optional, use ista instead of fista, false by default).
%            param.subgrad (optional, if not param.ista, use subradient descent instead of fista, false by default).
%            param.a, param.b (optional, if param.subgrad, the gradient step is a/(t+b)
%            also similar options as mexProximalTree
%
%            the function also implements the ADMM algorithm via an option param.admm=true. It is not documented
%            and you need to look at the source code to use it.
%
% Output:  W:  double dense p x n matrix or p x Nn matrix (for multi-logistic loss)
%
% Author: Julien Mairal, 2010


</FONT></PRE><H3 CLASS="subsection"><A NAME="toc21"></A><A NAME="htoc32">5.8</A>  Function mexFistaGraph</H3><P>
Given a matrix <I><B>X</B></I>=[<I><B>x</B></I><SUP>1</SUP>,…,<I><B>x</B><SUP>p</SUP></I>]<I><SUP>T</SUP></I> in ℝ<SUP><I>m</I> × <I>p</I></SUP>, and a matrix <I><B>Y</B></I>=[<I><B>y</B></I><SUP>1</SUP>,…,<I><B>y</B><SUP>n</SUP></I>], it solves the optimization problems presented in the previous section, with the same regularization functions as mexProximalGraph.
see usage details below:</P><PRE CLASS="verbatim"><FONT SIZE=2>% 
% Usage: W=mexFistaGraph(Y,X,W0,graph,param);
%
% Name: mexFistaGraph
%
% Description: mexFistaGraph solves sparse regularized problems.
%         X is a design matrix of size m x p
%         X=[x^1,...,x^n]', where the x_i's are the rows of X
%         Y=[y^1,...,y^n] is a matrix of size m x n
%         It implements the algorithms FISTA, ISTA and subgradient descent.
%
%         It implements the algorithms FISTA, ISTA and subgradient descent for solving
%
%           min_W  loss(W) + lambda psi(W)
%          
%         The function psi are those used by mexProximalGraph (see documentation)
%         for the loss functions, see the documentation of mexFistaFlat
%         
%         This function can also handle intercepts (last row of W is not regularized),
%         and/or non-negativity constraints on W.
%
% Inputs: Y:  double dense m x n matrix
%         X:  double dense or sparse m x p matrix   
%         W0:  double dense p x n matrix or p x Nn matrix (for multi-logistic loss)
%              initial guess
%         graph: struct (see documentation of mexProximalGraph)
%         param: struct
%            param.loss (choice of loss, see above)
%            param.regul (choice of regularization, see function mexProximalFlat)
%            param.lambda (regularization parameter)
%            param.lambda2 (optional, regularization parameter, 0 by default)
%            param.lambda3 (optional, regularization parameter, 0 by default)
%            param.verbose (optional, verbosity level, false by default)
%            param.intercept (optional, last row of U is not regularized,
%                false by default)
%            param.pos (optional, adds positivity constraints on the
%                coefficients, false by default)
%            param.numThreads (optional, number of threads for exploiting
%                multi-core / multi-cpus. By default, it takes the value -1,
%                which automatically selects all the available CPUs/cores).
%            param.max_it (optional, maximum number of iterations, 100 by default)
%            param.tol (optional, tolerance for stopping criteration, which is a relative duality gap
%                if it is available, or a relative change of parameters).
%            param.gamma (optional, multiplier for increasing the parameter L in fista, 1.5 by default)
%            param.L0 (optional, initial parameter L in fista, 0.1 by default, should be small enough)
%            param.fixed_step (deactive the line search for L in fista and use param.L0 instead)
%            param.compute_gram (optional, pre-compute X^TX, false by default).
%            param.intercept (optional, do not regularize last row of W, false by default).
%            param.ista (optional, use ista instead of fista, false by default).
%            param.subgrad (optional, if not param.ista, use subradient descent instead of fista, false by default).
%            param.a, param.b (optional, if param.subgrad, the gradient step is a/(t+b)
%            also similar options as mexProximalTree
%
%            the function also implements the ADMM algorithm via an option param.admm=true. It is not documented
%            and you need to look at the source code to use it.
%
%
% Output:  W:  double dense p x n matrix or p x Nn matrix (for multi-logistic loss)
%
% Author: Julien Mairal, 2010


</FONT></PRE><HR>
<A HREF="doc_spams004.html"><IMG SRC="previous_motif.gif" ALT="Previous"></A>
<A HREF="index.html"><IMG SRC="contents_motif.gif" ALT="Up"></A>
<A HREF="doc_spams006.html"><IMG SRC="next_motif.gif" ALT="Next"></A>
</BODY>
</HTML>
